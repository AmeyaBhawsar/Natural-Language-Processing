{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bcfe553",
   "metadata": {},
   "source": [
    "### Installthe libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff23c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sumy\n",
      "  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement transformer (from versions: none)\n",
      "ERROR: No matching distribution found for transformer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sumy\n",
      "  Using cached sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (4.36.2)\n",
      "Collecting docopt<0.7,>=0.6.1 (from sumy)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting breadability>=0.1.20 (from sumy)\n",
      "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sumy) (2.31.0)\n",
      "Collecting pycountry>=18.2.23 (from sumy)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: nltk>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from sumy) (3.8.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: chardet in c:\\programdata\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
      "Requirement already satisfied: lxml>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.9.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.7.0->sumy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.3/97.3 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.3 MB 10.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.0/6.3 MB 12.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.4/6.3 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.8/6.3 MB 10.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.3/6.3 MB 10.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.8/6.3 MB 10.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.2/6.3 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 10.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.1/6.3 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.0/6.3 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.5/6.3 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.3 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 9.4 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: breadability, docopt\n",
      "  Building wheel for breadability (setup.py): started\n",
      "  Building wheel for breadability (setup.py): finished with status 'done'\n",
      "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21739 sha256=38c2497abf2b18a7c9b3044598692c27d20a5667c9d48702dd6c7f636698ce75\n",
      "  Stored in directory: c:\\users\\administrator.dai-pc2\\appdata\\local\\pip\\cache\\wheels\\4d\\57\\58\\7e3d7fedf51fe248b7fcee3df6945ae28638e22cddf01eb92b\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13773 sha256=de621ef070faf75acb5d69f789deb737511caf14ee1e07acd3b67d33c85eb8a3\n",
      "  Stored in directory: c:\\users\\administrator.dai-pc2\\appdata\\local\\pip\\cache\\wheels\\1a\\b0\\8c\\4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "Successfully built breadability docopt\n",
      "Installing collected packages: docopt, pycountry, breadability, sumy\n",
      "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-24.6.1 sumy-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts breadability-3.11.exe, breadability.exe, breadability_test-3.11.exe and breadability_test.exe are installed in 'C:\\Users\\Administrator.DAI-PC2\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts sumy-3.10.exe, sumy.exe, sumy_eval-3.10.exe and sumy_eval.exe are installed in 'C:\\Users\\Administrator.DAI-PC2\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install sumy transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3897a219",
   "metadata": {},
   "source": [
    "### Extractive summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de0a9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the class\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5448bd",
   "metadata": {},
   "source": [
    "### using text rank summaizer algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b98c30ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import parser and tokenizers\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0209bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"The tiger (Panthera tigris) is the largest living cat species and a member of the genus Panthera native to Asia. It has a powerful, muscular body with a large head and paws, a long tail, and orange fur with black, mostly vertical stripes. It is traditionally classified into nine recent subspecies, though some recognise only two subspecies, mainland Asian tigers and island tigers of the Sunda Islands.\n",
    "\n",
    "Throughout the tiger's range, it inhabits mainly forests, from coniferous and temperate broadleaf and mixed forests in the Russian Far East and Northeast China to tropical and subtropical moist broadleaf forests on the Indian subcontinent and Southeast Asia. The tiger is an apex predator and preys mainly on ungulates such as deer and wild boar, which it takes by ambush. It lives a mostly solitary life and occupies home ranges, which it defends from individuals of the same sex. The range of a male tiger overlaps with that of multiple females with whom he has reproductive claims. Females give birth to usually two or three cubs that stay with their mother for about two years. When becoming independent, they leave their mother's home range and establish their own.\n",
    "\n",
    "Since the early 20th century, tiger populations have lost at least 93% of their historic range and are locally extinct in West and Central Asia, in large areas of China, and on the islands of Java and Bali. Today, the tiger's range is severely fragmented. It is listed as Endangered on the IUCN Red List of Threatened Species, as its range is thought to have declined by 53% to 68% since the late 1990s. Major reasons for this decline are habitat destruction and fragmentation due to deforestation, poaching for fur, and the illegal trade of tiger body parts for medicinal purposes. Tigers are also victims of human–wildlife conflict for attacking and preying on livestock in areas, where natural prey is scarce. The species is legally protected in all range countries, which have ratified conservation action plans, established anti-poaching patrols and schemes for monitoring tiger populations.\n",
    "\n",
    "The tiger is among the most popular of the world's charismatic megafauna. It has been kept in captivity since ancient times and has been trained to perform in circuses and other entertainment shows. The tiger featured prominently in the ancient mythology and folklore of cultures throughout its historic range and has continued to appear in culture worldwide.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6269496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The tiger (Panthera tigris) is the largest living cat species and a member of the genus Panthera native to Asia. It has a powerful, muscular body with a large head and paws, a long tail, and orange fur with black, mostly vertical stripes. It is traditionally classified into nine recent subspecies, though some recognise only two subspecies, mainland Asian tigers and island tigers of the Sunda Islands.\\n\\nThroughout the tiger's range, it inhabits mainly forests, from coniferous and temperate broadleaf and mixed forests in the Russian Far East and Northeast China to tropical and subtropical moist broadleaf forests on the Indian subcontinent and Southeast Asia. The tiger is an apex predator and preys mainly on ungulates such as deer and wild boar, which it takes by ambush. It lives a mostly solitary life and occupies home ranges, which it defends from individuals of the same sex. The range of a male tiger overlaps with that of multiple females with whom he has reproductive claims. Females give birth to usually two or three cubs that stay with their mother for about two years. When becoming independent, they leave their mother's home range and establish their own.\\n\\nSince the early 20th century, tiger populations have lost at least 93% of their historic range and are locally extinct in West and Central Asia, in large areas of China, and on the islands of Java and Bali. Today, the tiger's range is severely fragmented. It is listed as Endangered on the IUCN Red List of Threatened Species, as its range is thought to have declined by 53% to 68% since the late 1990s. Major reasons for this decline are habitat destruction and fragmentation due to deforestation, poaching for fur, and the illegal trade of tiger body parts for medicinal purposes. Tigers are also victims of human–wildlife conflict for attacking and preying on livestock in areas, where natural prey is scarce. The species is legally protected in all range countries, which have ratified conservation action plans, established anti-poaching patrols and schemes for monitoring tiger populations.\\n\\nThe tiger is among the most popular of the world's charismatic megafauna. It has been kept in captivity since ancient times and has been trained to perform in circuses and other entertainment shows. The tiger featured prominently in the ancient mythology and folklore of cultures throughout its historic range and has continued to appear in culture worldwide.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6c1b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f623693f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = sent_tokenize(text)\n",
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1ae527b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The tiger (Panthera tigris) is the largest living cat species and a member of the genus Panthera native to Asia.',\n",
       " 'It has a powerful, muscular body with a large head and paws, a long tail, and orange fur with black, mostly vertical stripes.',\n",
       " 'It is traditionally classified into nine recent subspecies, though some recognise only two subspecies, mainland Asian tigers and island tigers of the Sunda Islands.',\n",
       " \"Throughout the tiger's range, it inhabits mainly forests, from coniferous and temperate broadleaf and mixed forests in the Russian Far East and Northeast China to tropical and subtropical moist broadleaf forests on the Indian subcontinent and Southeast Asia.\",\n",
       " 'The tiger is an apex predator and preys mainly on ungulates such as deer and wild boar, which it takes by ambush.',\n",
       " 'It lives a mostly solitary life and occupies home ranges, which it defends from individuals of the same sex.',\n",
       " 'The range of a male tiger overlaps with that of multiple females with whom he has reproductive claims.',\n",
       " 'Females give birth to usually two or three cubs that stay with their mother for about two years.',\n",
       " \"When becoming independent, they leave their mother's home range and establish their own.\",\n",
       " 'Since the early 20th century, tiger populations have lost at least 93% of their historic range and are locally extinct in West and Central Asia, in large areas of China, and on the islands of Java and Bali.',\n",
       " \"Today, the tiger's range is severely fragmented.\",\n",
       " 'It is listed as Endangered on the IUCN Red List of Threatened Species, as its range is thought to have declined by 53% to 68% since the late 1990s.',\n",
       " 'Major reasons for this decline are habitat destruction and fragmentation due to deforestation, poaching for fur, and the illegal trade of tiger body parts for medicinal purposes.',\n",
       " 'Tigers are also victims of human–wildlife conflict for attacking and preying on livestock in areas, where natural prey is scarce.',\n",
       " 'The species is legally protected in all range countries, which have ratified conservation action plans, established anti-poaching patrols and schemes for monitoring tiger populations.',\n",
       " \"The tiger is among the most popular of the world's charismatic megafauna.\",\n",
       " 'It has been kept in captivity since ancient times and has been trained to perform in circuses and other entertainment shows.',\n",
       " 'The tiger featured prominently in the ancient mythology and folklore of cultures throughout its historic range and has continued to appear in culture worldwide.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f271b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialoze parser \n",
    "\n",
    "my_parser = PlaintextParser.from_string(text, Tokenizer('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45ab88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object\n",
    "\n",
    "text_rank_summarizer = TextRankSummarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22974a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract top 3 sentences\n",
    "\n",
    "summary = text_rank_summarizer(my_parser.document, sentences_count=3) #top 3 ranking sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c15615f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Sentence: Throughout the tiger's range, it inhabits mainly forests, from coniferous and temperate broadleaf and mixed forests in the Russian Far East and Northeast China to tropical and subtropical moist broadleaf forests on the Indian subcontinent and Southeast Asia.>, <Sentence: Since the early 20th century, tiger populations have lost at least 93% of their historic range and are locally extinct in West and Central Asia, in large areas of China, and on the islands of Java and Bali.>, <Sentence: The tiger featured prominently in the ancient mythology and folklore of cultures throughout its historic range and has continued to appear in culture worldwide.>)\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ede44050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Throughout the tiger's range, it inhabits mainly forests, from coniferous and temperate broadleaf and mixed forests in the Russian Far East and Northeast China to tropical and subtropical moist broadleaf forests on the Indian subcontinent and Southeast Asia. \n",
      "\n",
      "Since the early 20th century, tiger populations have lost at least 93% of their historic range and are locally extinct in West and Central Asia, in large areas of China, and on the islands of Java and Bali. \n",
      "\n",
      "The tiger featured prominently in the ancient mythology and folklore of cultures throughout its historic range and has continued to appear in culture worldwide. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in summary:\n",
    "    print(sent, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b562ddaa",
   "metadata": {},
   "source": [
    "## Lex Rank summarizer algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6ba49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.lex_rank import LexRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afbbc8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_rank_summarizer = LexRankSummarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee8e4c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = lex_rank_summarizer(my_parser.document, sentences_count=3) #top 3 ranking sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b8c6ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It has a powerful, muscular body with a large head and paws, a long tail, and orange fur with black, mostly vertical stripes. \n",
      "\n",
      "Females give birth to usually two or three cubs that stay with their mother for about two years. \n",
      "\n",
      "Since the early 20th century, tiger populations have lost at least 93% of their historic range and are locally extinct in West and Central Asia, in large areas of China, and on the islands of Java and Bali. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in summary:\n",
    "    print(sent, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4b12fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtext=''''वाघ मार्जार कुळातील प्राणी असून भारताचा राष्ट्रीय प्राणी आहे[२]. मार्जार कुळातील सर्वात मोठा प्राणी म्हणून याची गणना होते व अन्न साखळीतील सर्वोच्च स्थान वाघ भूषवतो. वाघ या नावाची व्युत्पत्ती संस्कृत मधील 'व्याघ्र' या शब्दावरून आली आहे. इंग्रजीत वाघाला 'टायगर असे म्हणतात. मराठीत भल्या मोठ्या वाघाला 'ढाण्या' वाघ म्हणतात. वाघ हा शिकार करण्यात परिपक्व आहे.\n",
    "\n",
    "इ.स. २०१० पासून जगभरात २९ जुलै हा जागतिक व्याघ्र दिन म्हणून पाळला जातो. भारतात वाघ हा संरक्षित प्राणी असून त्याची शिकार करणे हा दंडनीय अपराध आहे.\n",
    "\n",
    "एके काळी पश्चिमेस पूर्व अँटोलिया [३]प्रदेश पासून अमूर नदी [४]पात्रात आणि दक्षिणेस हिमालयाच्या पायथ्यापासून सुली बेटांपर्यंतच्या बालीपर्यंत सर्वत्र वाघ पसरले. २० व्या शतकाच्या सुरुवातीस, वाघाची संख्या पूर्वीहून ९३% ने कमी झाली आहे तसेच पश्चिम आणि मध्य आशियात, जावा आणि बाली बेटांमधून आणि आग्नेय, दक्षिण आशिया आणि चीनच्या मोठ्या भागांतून लोप पावली आहे. सध्याची वाघ प्रजाती भारतीय उपखंड आणि सुमात्रावरील सायबेरियन समशीतोष्ण जंगलांपासून ते उप-उष्णकटिबंधीय व उष्णकटिबंधीय जंगलांपर्यंत पसरलेली आहे. १९८६ पासून वाघाला आययूसीएन रेड लिस्टमध्ये लुप्तप्राय प्रजाती म्हणून सूचीबद्ध केले आहे. २०१५ पर्यंत जगातील प्रौढ वाघांची संख्या ३०६२ ते ३९४८ असावी असा अंदाज आहे. भारतात सध्या सर्वात अधिक वाघांची संख्या आहे. वाघांची संख्या कमी होण्याच्या मुख्य कारणांमध्ये त्यांचे प्राकृतिक आवास स्थान नष्ट करणे, खंडित करणे आणि शिकार करणे समाविष्ट आहे. काही देशांमधील अधिक दाट लोकवस्ती चे अतिक्रमण या ठिकाणी कारणीभूत आहे.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77ef9baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'वाघ मार्जार कुळातील प्राणी असून भारताचा राष्ट्रीय प्राणी आहे[२]. मार्जार कुळातील सर्वात मोठा प्राणी म्हणून याची गणना होते व अन्न साखळीतील सर्वोच्च स्थान वाघ भूषवतो. वाघ या नावाची व्युत्पत्ती संस्कृत मधील 'व्याघ्र' या शब्दावरून आली आहे. इंग्रजीत वाघाला 'टायगर असे म्हणतात. मराठीत भल्या मोठ्या वाघाला 'ढाण्या' वाघ म्हणतात. वाघ हा शिकार करण्यात परिपक्व आहे.\\n\\nइ.स. २०१० पासून जगभरात २९ जुलै हा जागतिक व्याघ्र दिन म्हणून पाळला जातो. भारतात वाघ हा संरक्षित प्राणी असून त्याची शिकार करणे हा दंडनीय अपराध आहे.\\n\\nएके काळी पश्चिमेस पूर्व अँटोलिया [३]प्रदेश पासून अमूर नदी [४]पात्रात आणि दक्षिणेस हिमालयाच्या पायथ्यापासून सुली बेटांपर्यंतच्या बालीपर्यंत सर्वत्र वाघ पसरले. २० व्या शतकाच्या सुरुवातीस, वाघाची संख्या पूर्वीहून ९३% ने कमी झाली आहे तसेच पश्चिम आणि मध्य आशियात, जावा आणि बाली बेटांमधून आणि आग्नेय, दक्षिण आशिया आणि चीनच्या मोठ्या भागांतून लोप पावली आहे. सध्याची वाघ प्रजाती भारतीय उपखंड आणि सुमात्रावरील सायबेरियन समशीतोष्ण जंगलांपासून ते उप-उष्णकटिबंधीय व उष्णकटिबंधीय जंगलांपर्यंत पसरलेली आहे. १९८६ पासून वाघाला आययूसीएन रेड लिस्टमध्ये लुप्तप्राय प्रजाती म्हणून सूचीबद्ध केले आहे. २०१५ पर्यंत जगातील प्रौढ वाघांची संख्या ३०६२ ते ३९४८ असावी असा अंदाज आहे. भारतात सध्या सर्वात अधिक वाघांची संख्या आहे. वाघांची संख्या कमी होण्याच्या मुख्य कारणांमध्ये त्यांचे प्राकृतिक आवास स्थान नष्ट करणे, खंडित करणे आणि शिकार करणे समाविष्ट आहे. काही देशांमधील अधिक दाट लोकवस्ती चे अतिक्रमण या ठिकाणी कारणीभूत आहे.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9babb771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_tokenize(mtext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "254adc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using text rank\n",
    "my_parser = PlaintextParser.from_string(mtext, Tokenizer('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9d7b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = text_rank_summarizer(my_parser.document, sentences_count=3) #top 3 ranking sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "968efb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Sentence: 'वाघ मार्जार कुळातील प्राणी असून भारताचा राष्ट्रीय प्राणी आहे[२].>,\n",
       " <Sentence: मार्जार कुळातील सर्वात मोठा प्राणी म्हणून याची गणना होते व अन्न साखळीतील सर्वोच्च स्थान वाघ भूषवतो.>,\n",
       " <Sentence: सध्याची वाघ प्रजाती भारतीय उपखंड आणि सुमात्रावरील सायबेरियन समशीतोष्ण जंगलांपासून ते उप-उष्णकटिबंधीय व उष्णकटिबंधीय जंगलांपर्यंत पसरलेली आहे.>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a452850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using lex rank\n",
    "my_parser = PlaintextParser.from_string(mtext, Tokenizer('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7729d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = lex_rank_summarizer(my_parser.document, sentences_count=3) #top 3 ranking sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a093750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Sentence: 'वाघ मार्जार कुळातील प्राणी असून भारताचा राष्ट्रीय प्राणी आहे[२].>,\n",
       " <Sentence: मार्जार कुळातील सर्वात मोठा प्राणी म्हणून याची गणना होते व अन्न साखळीतील सर्वोच्च स्थान वाघ भूषवतो.>,\n",
       " <Sentence: सध्याची वाघ प्रजाती भारतीय उपखंड आणि सुमात्रावरील सायबेरियन समशीतोष्ण जंगलांपासून ते उप-उष्णकटिबंधीय व उष्णकटिबंधीय जंगलांपर्यंत पसरलेली आहे.>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d0cc7c",
   "metadata": {},
   "source": [
    "## LSA Summarizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0278b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.lsa import LsaSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50e9e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_summarizer = LsaSummarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4bb0a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_parser = PlaintextParser.from_string(text, Tokenizer('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7109c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = lsa_summarizer(my_parser.document, sentences_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1249572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is listed as Endangered on the IUCN Red List of Threatened Species, as its range is thought to have declined by 53% to 68% since the late 1990s. \n",
      "\n",
      "Tigers are also victims of human–wildlife conflict for attacking and preying on livestock in areas, where natural prey is scarce. \n",
      "\n",
      "The species is legally protected in all range countries, which have ratified conservation action plans, established anti-poaching patrols and schemes for monitoring tiger populations. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in summary:\n",
    "    print(sent, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0370fc5",
   "metadata": {},
   "source": [
    "### Abstractive Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6ba6e",
   "metadata": {},
   "source": [
    "### Using GPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a7f92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7fd485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Pipeline in module transformers.pipelines.base:\n",
      "\n",
      "class Pipeline(_ScikitCompat)\n",
      " |  Pipeline(model: Union[ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')], tokenizer: Optional[transformers.tokenization_utils.PreTrainedTokenizer] = None, feature_extractor: Optional[ForwardRef('SequenceFeatureExtractor')] = None, image_processor: Optional[transformers.image_processing_utils.BaseImageProcessor] = None, modelcard: Optional[transformers.modelcard.ModelCard] = None, framework: Optional[str] = None, task: str = '', args_parser: transformers.pipelines.base.ArgumentHandler = None, device: Union[int, ForwardRef('torch.device')] = None, torch_dtype: Union[str, ForwardRef('torch.dtype'), NoneType] = None, binary_output: bool = False, **kwargs)\n",
      " |  \n",
      " |  The Pipeline class is the class from which all pipelines inherit. Refer to this class for methods shared across\n",
      " |  different pipelines.\n",
      " |  \n",
      " |  Base class implementing pipelined operations. Pipeline workflow is defined as a sequence of the following\n",
      " |  operations:\n",
      " |  \n",
      " |      Input -> Tokenization -> Model Inference -> Post-Processing (task dependent) -> Output\n",
      " |  \n",
      " |  Pipeline supports running on CPU or GPU through the device argument (see below).\n",
      " |  \n",
      " |  Some pipeline, like for instance [`FeatureExtractionPipeline`] (`'feature-extraction'`) output large tensor object\n",
      " |  as nested-lists. In order to avoid dumping such large structure as textual data we provide the `binary_output`\n",
      " |  constructor argument. If set to `True`, the output will be stored in the pickle format.\n",
      " |  \n",
      " |  Arguments:\n",
      " |      model ([`PreTrainedModel`] or [`TFPreTrainedModel`]):\n",
      " |          The model that will be used by the pipeline to make predictions. This needs to be a model inheriting from\n",
      " |          [`PreTrainedModel`] for PyTorch and [`TFPreTrainedModel`] for TensorFlow.\n",
      " |      tokenizer ([`PreTrainedTokenizer`]):\n",
      " |          The tokenizer that will be used by the pipeline to encode data for the model. This object inherits from\n",
      " |          [`PreTrainedTokenizer`].\n",
      " |      modelcard (`str` or [`ModelCard`], *optional*):\n",
      " |          Model card attributed to the model for this pipeline.\n",
      " |      framework (`str`, *optional*):\n",
      " |          The framework to use, either `\"pt\"` for PyTorch or `\"tf\"` for TensorFlow. The specified framework must be\n",
      " |          installed.\n",
      " |  \n",
      " |          If no framework is specified, will default to the one currently installed. If no framework is specified and\n",
      " |          both frameworks are installed, will default to the framework of the `model`, or to PyTorch if no model is\n",
      " |          provided.\n",
      " |      task (`str`, defaults to `\"\"`):\n",
      " |          A task-identifier for the pipeline.\n",
      " |      num_workers (`int`, *optional*, defaults to 8):\n",
      " |          When the pipeline will use *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number of\n",
      " |          workers to be used.\n",
      " |      batch_size (`int`, *optional*, defaults to 1):\n",
      " |          When the pipeline will use *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of\n",
      " |          the batch to use, for inference this is not always beneficial, please read [Batching with\n",
      " |          pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching) .\n",
      " |      args_parser ([`~pipelines.ArgumentHandler`], *optional*):\n",
      " |          Reference to the object in charge of parsing supplied pipeline parameters.\n",
      " |      device (`int`, *optional*, defaults to -1):\n",
      " |          Device ordinal for CPU/GPU supports. Setting this to -1 will leverage CPU, a positive will run the model on\n",
      " |          the associated CUDA device id. You can pass native `torch.device` or a `str` too.\n",
      " |      binary_output (`bool`, *optional*, defaults to `False`):\n",
      " |          Flag indicating if the output the pipeline should happen in a binary format (i.e., pickle) or as raw text.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Pipeline\n",
      " |      _ScikitCompat\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, num_workers=None, batch_size=None, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __init__(self, model: Union[ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')], tokenizer: Optional[transformers.tokenization_utils.PreTrainedTokenizer] = None, feature_extractor: Optional[ForwardRef('SequenceFeatureExtractor')] = None, image_processor: Optional[transformers.image_processing_utils.BaseImageProcessor] = None, modelcard: Optional[transformers.modelcard.ModelCard] = None, framework: Optional[str] = None, task: str = '', args_parser: transformers.pipelines.base.ArgumentHandler = None, device: Union[int, ForwardRef('torch.device')] = None, torch_dtype: Union[str, ForwardRef('torch.dtype'), NoneType] = None, binary_output: bool = False, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  check_model_type(self, supported_models: Union[List[str], dict])\n",
      " |      Check if the model class is in supported by the pipeline.\n",
      " |      \n",
      " |      Args:\n",
      " |          supported_models (`List[str]` or `dict`):\n",
      " |              The list of models supported by the pipeline, or a dictionary with model class values.\n",
      " |  \n",
      " |  device_placement(self)\n",
      " |      Context Manager allowing tensor allocation on the user-specified device in framework agnostic way.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Context manager\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      ```python\n",
      " |      # Explicitly ask for tensor allocation on CUDA device :0\n",
      " |      pipe = pipeline(..., device=0)\n",
      " |      with pipe.device_placement():\n",
      " |          # Every framework specific tensor allocation will be done on the request device\n",
      " |          output = pipe(...)\n",
      " |      ```\n",
      " |  \n",
      " |  ensure_tensor_on_device(self, **inputs)\n",
      " |      Ensure PyTorch tensors are on the specified device.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs (keyword arguments that should be `torch.Tensor`, the rest is ignored):\n",
      " |              The tensors to place on `self.device`.\n",
      " |          Recursive on lists **only**.\n",
      " |      \n",
      " |      Return:\n",
      " |          `Dict[str, torch.Tensor]`: The same as `inputs` but on the proper device.\n",
      " |  \n",
      " |  forward(self, model_inputs, **forward_params)\n",
      " |  \n",
      " |  get_inference_context(self)\n",
      " |  \n",
      " |  get_iterator(self, inputs, num_workers: int, batch_size: int, preprocess_params, forward_params, postprocess_params)\n",
      " |  \n",
      " |  iterate(self, inputs, preprocess_params, forward_params, postprocess_params)\n",
      " |  \n",
      " |  postprocess(self, model_outputs: transformers.utils.generic.ModelOutput, **postprocess_parameters: Dict) -> Any\n",
      " |      Postprocess will receive the raw outputs of the `_forward` method, generally tensors, and reformat them into\n",
      " |      something more friendly. Generally it will output a list or a dict or results (containing just strings and\n",
      " |      numbers).\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Scikit / Keras interface to transformers' pipelines. This method will forward to __call__().\n",
      " |  \n",
      " |  preprocess(self, input_: Any, **preprocess_parameters: Dict) -> Dict[str, Union[List[ForwardRef('GenericTensor')], ForwardRef('torch.Tensor'), ForwardRef('tf.Tensor')]]\n",
      " |      Preprocess will take the `input_` of a specific pipeline and return a dictionary of everything necessary for\n",
      " |      `_forward` to run properly. It should contain at least one tensor, but might have arbitrary other items.\n",
      " |  \n",
      " |  run_multi(self, inputs, preprocess_params, forward_params, postprocess_params)\n",
      " |  \n",
      " |  run_single(self, inputs, preprocess_params, forward_params, postprocess_params)\n",
      " |  \n",
      " |  save_pretrained(self, save_directory: str, safe_serialization: bool = True)\n",
      " |      Save the pipeline's model and tokenizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          save_directory (`str`):\n",
      " |              A path to the directory where to saved. It will be created if it doesn't exist.\n",
      " |          safe_serialization (`str`):\n",
      " |              Whether to save the model using `safetensors` or the traditional way for PyTorch or Tensorflow.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Scikit / Keras interface to transformers' pipelines. This method will forward to __call__().\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset({'_forward', '_sanitize_parameters', '...\n",
      " |  \n",
      " |  default_input_names = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _ScikitCompat:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f1c24832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\Users\\Administrator.DAI-PC2\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7245ef7aa804ee5adca9e047e1c4207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator.DAI-PC2\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Administrator.DAI-PC2\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ebd40aaa80466994a39d48d24b8b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.huggingface.co/sshleifer/distilbart-cnn-12-6/3bac65d18c99463302d12ca75c2220ea714f9c81ce235f205fa818efe71df6ea?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1718081474&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxODA4MTQ3NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9zc2hsZWlmZXIvZGlzdGlsYmFydC1jbm4tMTItNi8zYmFjNjVkMThjOTk0NjMzMDJkMTJjYTc1YzIyMjBlYTcxNGY5YzgxY2UyMzVmMjA1ZmE4MThlZmU3MWRmNmVhP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=qTcubSaAU237deUK1ChU5wCx8e4GgKq2yLHh10HTA1ZU3jNaHYA1vTPxZc8W%7E7cCLl7vHdCoI%7E%7EZPLp4WRYU5BepSwB5gGOJNfna17QZd8LgYOyxn%7EX8DcTBOjyAEk17GPy6Kv0mO5nA8-UmrA3YFvjERCh-b2f%7EMt5FtKUVNThZ3GgcYY5DQHxIy0%7EPIu75dl2YEfZeeqBpSF%7E4FIxvNQN8MbeUV%7EvBAPHtv8MPKUpMFFO6AAWyZ1mpO4U2sbW4iEZuc-xAQcpB%7EIkSO04kSdVGr5FRH94xv-I6xiOFlA2OyH14OideqmhVX2TfmXyQEU7rYVxZ6iiBbep9CKOj7g__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2aac8e46f6a4cbca4e420f9d70738d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:  20%|#9        | 241M/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13c77d359fb45b696873daf543975a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640d35560889439f8d58fe8b6cd0a9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce0b338bae3457abaaa453b3ee64b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_summarizer=pipeline('summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4dfd75f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=text_summarizer(text,max_length=400,min_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "999206d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' The tiger (Panthera tigris) is the largest living cat species and a member of the genus Panthera native to Asia . It has a powerful, muscular body with a large head and paws, a long tail, and orange fur with black, mostly vertical stripes . It is listed as Endangered on the IUCN Red List of Threatened Species . Tiger populations have lost at least 93% of their historic range and are locally extinct in West and Central Asia, in large areas of China, and on the islands of Java and Bali .'}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dde144d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pipeline in module transformers.pipelines:\n",
      "\n",
      "pipeline(task: str = None, model: Union[str, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel'), NoneType] = None, config: Union[str, transformers.configuration_utils.PretrainedConfig, NoneType] = None, tokenizer: Union[str, transformers.tokenization_utils.PreTrainedTokenizer, ForwardRef('PreTrainedTokenizerFast'), NoneType] = None, feature_extractor: Union[str, ForwardRef('SequenceFeatureExtractor'), NoneType] = None, image_processor: Union[str, transformers.image_processing_utils.BaseImageProcessor, NoneType] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Union[str, bool, NoneType] = None, device: Union[int, str, ForwardRef('torch.device'), NoneType] = None, device_map=None, torch_dtype=None, trust_remote_code: Optional[bool] = None, model_kwargs: Dict[str, Any] = None, pipeline_class: Optional[Any] = None, **kwargs) -> transformers.pipelines.base.Pipeline\n",
      "    Utility factory method to build a [`Pipeline`].\n",
      "    \n",
      "    Pipelines are made of:\n",
      "    \n",
      "        - A [tokenizer](tokenizer) in charge of mapping raw textual input to token.\n",
      "        - A [model](model) to make predictions from the inputs.\n",
      "        - Some (optional) post processing for enhancing model's output.\n",
      "    \n",
      "    Args:\n",
      "        task (`str`):\n",
      "            The task defining which pipeline will be returned. Currently accepted tasks are:\n",
      "    \n",
      "            - `\"audio-classification\"`: will return a [`AudioClassificationPipeline`].\n",
      "            - `\"automatic-speech-recognition\"`: will return a [`AutomaticSpeechRecognitionPipeline`].\n",
      "            - `\"conversational\"`: will return a [`ConversationalPipeline`].\n",
      "            - `\"depth-estimation\"`: will return a [`DepthEstimationPipeline`].\n",
      "            - `\"document-question-answering\"`: will return a [`DocumentQuestionAnsweringPipeline`].\n",
      "            - `\"feature-extraction\"`: will return a [`FeatureExtractionPipeline`].\n",
      "            - `\"fill-mask\"`: will return a [`FillMaskPipeline`]:.\n",
      "            - `\"image-classification\"`: will return a [`ImageClassificationPipeline`].\n",
      "            - `\"image-segmentation\"`: will return a [`ImageSegmentationPipeline`].\n",
      "            - `\"image-to-image\"`: will return a [`ImageToImagePipeline`].\n",
      "            - `\"image-to-text\"`: will return a [`ImageToTextPipeline`].\n",
      "            - `\"mask-generation\"`: will return a [`MaskGenerationPipeline`].\n",
      "            - `\"object-detection\"`: will return a [`ObjectDetectionPipeline`].\n",
      "            - `\"question-answering\"`: will return a [`QuestionAnsweringPipeline`].\n",
      "            - `\"summarization\"`: will return a [`SummarizationPipeline`].\n",
      "            - `\"table-question-answering\"`: will return a [`TableQuestionAnsweringPipeline`].\n",
      "            - `\"text2text-generation\"`: will return a [`Text2TextGenerationPipeline`].\n",
      "            - `\"text-classification\"` (alias `\"sentiment-analysis\"` available): will return a\n",
      "              [`TextClassificationPipeline`].\n",
      "            - `\"text-generation\"`: will return a [`TextGenerationPipeline`]:.\n",
      "            - `\"text-to-audio\"` (alias `\"text-to-speech\"` available): will return a [`TextToAudioPipeline`]:.\n",
      "            - `\"token-classification\"` (alias `\"ner\"` available): will return a [`TokenClassificationPipeline`].\n",
      "            - `\"translation\"`: will return a [`TranslationPipeline`].\n",
      "            - `\"translation_xx_to_yy\"`: will return a [`TranslationPipeline`].\n",
      "            - `\"video-classification\"`: will return a [`VideoClassificationPipeline`].\n",
      "            - `\"visual-question-answering\"`: will return a [`VisualQuestionAnsweringPipeline`].\n",
      "            - `\"zero-shot-classification\"`: will return a [`ZeroShotClassificationPipeline`].\n",
      "            - `\"zero-shot-image-classification\"`: will return a [`ZeroShotImageClassificationPipeline`].\n",
      "            - `\"zero-shot-audio-classification\"`: will return a [`ZeroShotAudioClassificationPipeline`].\n",
      "            - `\"zero-shot-object-detection\"`: will return a [`ZeroShotObjectDetectionPipeline`].\n",
      "    \n",
      "        model (`str` or [`PreTrainedModel`] or [`TFPreTrainedModel`], *optional*):\n",
      "            The model that will be used by the pipeline to make predictions. This can be a model identifier or an\n",
      "            actual instance of a pretrained model inheriting from [`PreTrainedModel`] (for PyTorch) or\n",
      "            [`TFPreTrainedModel`] (for TensorFlow).\n",
      "    \n",
      "            If not provided, the default for the `task` will be loaded.\n",
      "        config (`str` or [`PretrainedConfig`], *optional*):\n",
      "            The configuration that will be used by the pipeline to instantiate the model. This can be a model\n",
      "            identifier or an actual pretrained model configuration inheriting from [`PretrainedConfig`].\n",
      "    \n",
      "            If not provided, the default configuration file for the requested model will be used. That means that if\n",
      "            `model` is given, its default configuration will be used. However, if `model` is not supplied, this\n",
      "            `task`'s default model's config is used instead.\n",
      "        tokenizer (`str` or [`PreTrainedTokenizer`], *optional*):\n",
      "            The tokenizer that will be used by the pipeline to encode data for the model. This can be a model\n",
      "            identifier or an actual pretrained tokenizer inheriting from [`PreTrainedTokenizer`].\n",
      "    \n",
      "            If not provided, the default tokenizer for the given `model` will be loaded (if it is a string). If `model`\n",
      "            is not specified or not a string, then the default tokenizer for `config` is loaded (if it is a string).\n",
      "            However, if `config` is also not given or not a string, then the default tokenizer for the given `task`\n",
      "            will be loaded.\n",
      "        feature_extractor (`str` or [`PreTrainedFeatureExtractor`], *optional*):\n",
      "            The feature extractor that will be used by the pipeline to encode data for the model. This can be a model\n",
      "            identifier or an actual pretrained feature extractor inheriting from [`PreTrainedFeatureExtractor`].\n",
      "    \n",
      "            Feature extractors are used for non-NLP models, such as Speech or Vision models as well as multi-modal\n",
      "            models. Multi-modal models will also require a tokenizer to be passed.\n",
      "    \n",
      "            If not provided, the default feature extractor for the given `model` will be loaded (if it is a string). If\n",
      "            `model` is not specified or not a string, then the default feature extractor for `config` is loaded (if it\n",
      "            is a string). However, if `config` is also not given or not a string, then the default feature extractor\n",
      "            for the given `task` will be loaded.\n",
      "        framework (`str`, *optional*):\n",
      "            The framework to use, either `\"pt\"` for PyTorch or `\"tf\"` for TensorFlow. The specified framework must be\n",
      "            installed.\n",
      "    \n",
      "            If no framework is specified, will default to the one currently installed. If no framework is specified and\n",
      "            both frameworks are installed, will default to the framework of the `model`, or to PyTorch if no model is\n",
      "            provided.\n",
      "        revision (`str`, *optional*, defaults to `\"main\"`):\n",
      "            When passing a task name or a string model identifier: The specific model version to use. It can be a\n",
      "            branch name, a tag name, or a commit id, since we use a git-based system for storing models and other\n",
      "            artifacts on huggingface.co, so `revision` can be any identifier allowed by git.\n",
      "        use_fast (`bool`, *optional*, defaults to `True`):\n",
      "            Whether or not to use a Fast tokenizer if possible (a [`PreTrainedTokenizerFast`]).\n",
      "        use_auth_token (`str` or *bool*, *optional*):\n",
      "            The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n",
      "            when running `huggingface-cli login` (stored in `~/.huggingface`).\n",
      "        device (`int` or `str` or `torch.device`):\n",
      "            Defines the device (*e.g.*, `\"cpu\"`, `\"cuda:1\"`, `\"mps\"`, or a GPU ordinal rank like `1`) on which this\n",
      "            pipeline will be allocated.\n",
      "        device_map (`str` or `Dict[str, Union[int, str, torch.device]`, *optional*):\n",
      "            Sent directly as `model_kwargs` (just a simpler shortcut). When `accelerate` library is present, set\n",
      "            `device_map=\"auto\"` to compute the most optimized `device_map` automatically (see\n",
      "            [here](https://huggingface.co/docs/accelerate/main/en/package_reference/big_modeling#accelerate.cpu_offload)\n",
      "            for more information).\n",
      "    \n",
      "            <Tip warning={true}>\n",
      "    \n",
      "            Do not use `device_map` AND `device` at the same time as they will conflict\n",
      "    \n",
      "            </Tip>\n",
      "    \n",
      "        torch_dtype (`str` or `torch.dtype`, *optional*):\n",
      "            Sent directly as `model_kwargs` (just a simpler shortcut) to use the available precision for this model\n",
      "            (`torch.float16`, `torch.bfloat16`, ... or `\"auto\"`).\n",
      "        trust_remote_code (`bool`, *optional*, defaults to `False`):\n",
      "            Whether or not to allow for custom code defined on the Hub in their own modeling, configuration,\n",
      "            tokenization or even pipeline files. This option should only be set to `True` for repositories you trust\n",
      "            and in which you have read the code, as it will execute code present on the Hub on your local machine.\n",
      "        model_kwargs (`Dict[str, Any]`, *optional*):\n",
      "            Additional dictionary of keyword arguments passed along to the model's `from_pretrained(...,\n",
      "            **model_kwargs)` function.\n",
      "        kwargs (`Dict[str, Any]`, *optional*):\n",
      "            Additional keyword arguments passed along to the specific pipeline init (see the documentation for the\n",
      "            corresponding pipeline class for possible values).\n",
      "    \n",
      "    Returns:\n",
      "        [`Pipeline`]: A suitable pipeline for the task.\n",
      "    \n",
      "    Examples:\n",
      "    \n",
      "    ```python\n",
      "    >>> from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
      "    \n",
      "    >>> # Sentiment analysis pipeline\n",
      "    >>> analyzer = pipeline(\"sentiment-analysis\")\n",
      "    \n",
      "    >>> # Question answering pipeline, specifying the checkpoint identifier\n",
      "    >>> oracle = pipeline(\n",
      "    ...     \"question-answering\", model=\"distilbert-base-cased-distilled-squad\", tokenizer=\"bert-base-cased\"\n",
      "    ... )\n",
      "    \n",
      "    >>> # Named entity recognition pipeline, passing in a specific model and tokenizer\n",
      "    >>> model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
      "    >>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
      "    >>> recognizer = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
      "    ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e23089d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The tiger (Panthera tigris) is the largest living cat species and a member of the genus Panthera native to Asia . It has a powerful, muscular body with a large head and paws, a long tail, and orange fur with black, mostly vertical stripes . It is listed as Endangered on the IUCN Red List of Threatened Species . Tiger populations have lost at least 93% of their historic range and are locally extinct in West and Central Asia, in large areas of China, and on the islands of Java and Bali .'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264156b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
